{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(list):\n",
    "  def __init__(self, word_list, comma_split_special_tokens):\n",
    "    special_tokens = []\n",
    "    for token_id, token in enumerate(comma_split_special_tokens.split(':')):\n",
    "      special_tokens.append(f'<{token}>')\n",
    "      setattr(self, token, f'<{token}>')\n",
    "      setattr(self, f'{token}_id', token_id)\n",
    "\n",
    "    super().__init__(special_tokens + word_list)\n",
    "    self.dictionary = {word : index for index, word in enumerate(self) if word not in special_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokiPonaVocabulary(Vocabulary):\n",
    "  def __init__(self, comma_split_special_tokens = 'sep:num:prp'):\n",
    "    all_words = ' '.join([\n",
    "        'a akesi ala alasa ali anpa ante anu awen e en esun',\n",
    "        'ijo ike ilo insa jaki jan jelo jo kala kalama kama kasi',\n",
    "        'ken kepeken kili kiwen ko kon kule kulupu kute la lape laso',\n",
    "        'lawa len lete li lili linja lipu loje lon luka lukin lupa',\n",
    "        'ma mama mani meli mi mije moku moli monsi mu mun musi',\n",
    "        'mute nanpa nasa nasin nena ni nimi noka o olin ona open',\n",
    "        'pakala pali palisa pan pana pi pilin pimeja pini pipi poka poki',\n",
    "        'pona pu sama seli selo seme sewi sijelo sike sin sina sinpin',\n",
    "        'sitelen sona soweli suli suno supa suwi tan taso tawa telo tenpo',\n",
    "        'toki tomo tu unpa uta utala walo wan waso wawa weka wile'])\n",
    "    super().__init__(all_words.split(), comma_split_special_tokens=comma_split_special_tokens)\n",
    "    self.dictionary['ale'] = self.dictionary['ali']\n",
    "    self.dictionary['oko'] = self.dictionary['lukin']\n",
    "    self.dictionary['kin'] = self.dictionary['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class IloTunimiParsingException(Exception):\n",
    "  pass\n",
    "\n",
    "class IloTunimi:\n",
    "  def __init__(self):\n",
    "    self.vocab = TokiPonaVocabulary()\n",
    "    self.prp_pattern = re.compile(r'^([AIUEO]|[KSNPML][aiueo]|[TJ][aueo]|W[aie])n?(([ksnpml][aiueo]|[tj][aueo]|w[aie])n?)*$')\n",
    "\n",
    "  def convert(self, x):\n",
    "    if x in {'.', '!', '?', ':'}:\n",
    "      return self.vocab.sep_id\n",
    "    x = re.sub('[^0-9A-Za-z]', '', x)\n",
    "    if x == '':\n",
    "      return None\n",
    "    elif x in self.vocab.dictionary:\n",
    "      return self.vocab.dictionary[x]\n",
    "    elif x.isdecimal():\n",
    "      return self.vocab.num_id\n",
    "    elif self.prp_pattern.match(x) and ('nm' not in x) and ('nn' not in x):\n",
    "      return self.vocab.prp_id\n",
    "    else:\n",
    "      raise IloTunimiParsingException()\n",
    "\n",
    "  def __call__(self, xs):\n",
    "    xs = xs.strip()\n",
    "    xs = re.sub(r'([.!?:])', ' \\\\1 ', xs)\n",
    "    xs = xs.split()\n",
    "    ys = []\n",
    "    for x in xs:\n",
    "      x = self.convert(x)\n",
    "      if x is not None:\n",
    "        ys.append(self.vocab[x])\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "  def __init__(self, src, trg, terms):\n",
    "    self.src = src\n",
    "    self.trg = trg\n",
    "    self.terms = set(terms)\n",
    "\n",
    "class RRG:\n",
    "  def __init__(self):\n",
    "    self.rules = []\n",
    "    self.finals = []\n",
    "\n",
    "  def extend_finals(self, finals):\n",
    "    self.finals += finals\n",
    "\n",
    "  def add(self, src, terms, trg):\n",
    "    self.rules.append(Rule(src, trg, terms))\n",
    "\n",
    "  def update_state_list(self, word, old_state_list):\n",
    "    new_state_list = []\n",
    "    for rule in self.rules:\n",
    "      if word in rule.terms:\n",
    "        new_state_list.append(rule.trg)\n",
    "    return new_state_list\n",
    "\n",
    "  def __call__(self, sent, start='S'):\n",
    "    state_list = [start]\n",
    "    tmp = ' '.join(state_list)\n",
    "    for word in sent:\n",
    "      tmp += ' --{}--> '.format(word)\n",
    "      state_list = self.update_state_list(word, state_list)\n",
    "      tmp += ' '.join(state_list)\n",
    "    print(tmp)\n",
    "    return any(state in self.finals for state in state_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S --mi--> MS --sona--> V1 --ala--> A1 --<sep>--> E\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = IloTunimi()\n",
    "G = RRG()\n",
    "G.extend_finals('E')\n",
    "G.add('S', ['mi', 'sina'], 'MS')\n",
    "G.add('MS', ['sona'], 'V1')\n",
    "G.add('V1', ['ala'], 'A1')\n",
    "G.add('A1', ['<sep>'], 'E')\n",
    "G(tokenizer('mi sona ala.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
